Defination by Arthur Samuel :
machine learning as the field of study that gives computers the ability to learn without being explicitly programmed. 
Defination by Tom Mitchell :
A computer program is said to learn from experience E with respect to
some task T and some performance measure P, if its performance on T,
as measured by P, improves with experience E. 

Samuel's claim to fame was that back in the 1950, he wrote a checkers playing
program and the amazing thing about this checkers playing program
was that Arthur Samuel himself wasn't a very good checkers player.
But what he did was he had to programmed maybe tens of thousands of games against
himself, and by watching what sorts of board positions tended to lead to wins and
what sort of board positions tended to lead to losses,
the checkers playing program learned over time what are good board positions and
what are bad board positions.
And eventually learn to play checkers better than the Arthur Samuel
himself was able to.This was a remarkable result.
Arthur Samuel himself turns out not to be a very good checkers player.
But because a computer has the patience to play tens of thousands of
games against itself, no human has the patience to play that many games.
By doing this, a computer was able to get so much checkers playing experience
that it eventually became a better checkers player than Arthur himself.

Example: playing checkers.

E = the experience of playing many games of checkers

T = the task of playing checkers.

P = the probability that the program will win the next game.

In general, any machine learning problem can be assigned to one of two broad classifications:

Supervised learning and Unsupervised learning.

It turns out that in supervised learning,
the idea is we're going to teach the computer how to do something.
Whereas in unsupervised learning, we're going to let it learn by itself. 